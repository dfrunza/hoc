var Token keyword_list[] = 
{
  {TokenKind_If, "if"},
  {TokenKind_Else, "else"},
  {TokenKind_While, "while"},
  {TokenKind_For, "for"},
  {TokenKind_Return, "return"},
  {TokenKind_Break, "break"},
  {TokenKind_Include, "include"},
  {TokenKind_True, "true"},
  {TokenKind_False, "false"},
  {TokenKind_Proc, "proc"},
  {TokenKind_Var, "var"},
  {TokenKind_Struct, "struct"},
  {TokenKind_Enum, "enum"},
  {TokenKind__Null, 0},
};

var char* simple_lexeme_list[] =
{
  "(null)", ".", "[", "]", "(", ")", "{", "}", ";", ":", ",", "%", "*", "*", "/", "_",
  "+", "++", "-", "-", "--", "!", "!=", "=", "==", ">", ">=", "<", "<=", "&", "&", "&&", "|", "||",
  unk_char,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
};

var char unk_char[2] = {};

proc Token*
lookup_keyword(Token* list, char* lexeme)
{
  var Token* result = 0;
  var Token* token;

  for(int i = 0;
      (token = &list[i]).kind;
      token = &list[++i])
  {
    if(cstr_match(lexeme, token.lexeme))
    {
      result = token;
      break;
    }
  }
  return result;
}

proc Token*
get_prev_token(TokenStream* input, int index)
{
  assert(index == 0 || index == 1);
  return &input.prev_tokens[index];
}

proc bool32
is_keyword(TokenKind token_kind)
{
  return (token_kind > TokenKind__KeywordBegin) && (token_kind < TokenKind__KeywordEnd);
}

proc char*
install_id(MemoryArena* arena, char* begin_char, char* end_char)
{
  assert(end_char >= begin_char);

  var size_t len = end_char - begin_char + 1;
  var char* lexeme = mem_push_struct(arena, char, len + 1);
  cstr_copy_substr(lexeme, begin_char, end_char);
  return lexeme;
}

proc char*
install_dquot_str(MemoryArena* arena, char* begin_char, char* end_char)
{
  assert(end_char >= begin_char);
  assert(*begin_char == "'" && *end_char == "'"); 
  var size_t len = (end_char - begin_char + 1) - 2;
  var char* lexeme = mem_push_struct(arena, char, len + 1);

  var char* dest_str = lexeme;
  var char* src_str = begin_char+1;
  for(uint i = 0; i < len; i++)
  {
    *dest_str++ = *src_str++;
  }
  cstr_copy_substr(lexeme, begin_char+1, end_char-1);
  return lexeme;
}

proc void
token_stream_init(TokenStream* token_stream, char* text, char* file_path)
{
  token_stream.text = text;
  token_stream.cursor = token_stream.text;
  var SourceLocation* src_loc = &token_stream.src_loc;
  src_loc.line_nr = 1;
  src_loc.file_path = file_path;
}

proc bool
is_leading_unary_token(TokenKind token)
{
  return token == TokenKind_Equals ||
      token == TokenKind_EqualsEquals ||
      token == TokenKind_Semicolon ||
      token == TokenKind_OpenParens ||
      token == TokenKind_OpenBracket ||
      token == TokenKind_OpenBrace ||
      token == TokenKind_Star ||
      token == TokenKind_Plus ||
      token == TokenKind_Comma ||
      token == TokenKind_FwdSlash ||
      token == TokenKind_Return ||
      token == TokenKind_Pointer ||
      token == TokenKind_AddressOf ||
      token == TokenKind_NegativeSign ||
      token == TokenKind_AmpersandAmpersand ||
      token == TokenKind_AngleLeft ||
      token == TokenKind_AngleLeftEquals ||
      token == TokenKind_AngleRight ||
      token == TokenKind_AngleRightEquals ||
      token == TokenKind_Pipe ||
      token == TokenKind_PipePipe ||
      token == TokenKind_Percent ||
      token == TokenKind_FwdSlash ||
      token == TokenKind_Exclam ||
      token == TokenKind_ExclamEquals;
}

proc void
get_next_token(MemoryArena* arena, TokenStream* input)
{
  input.prev_tokens[1] = input.prev_tokens[0];
  input.prev_tokens[0] = input.token;
  mem_zero(&input.token);
  var SourceLocation* src_loc = &input.src_loc;
  src_loc.src_line = input.cursor;
  var char c;

  var Token* token = &input.token;
  c = *input.cursor;
  while(c == " " || c == "\t" ||
        c == "\r" || c == "\n")
  {
    if(c == "\n")
    {
      src_loc.line_nr++;
      src_loc.src_line = input.cursor;
    }
    c = *(++input.cursor);
  }

  if(char_is_letter(c) || c == "_")
  {
    var char* begin_char = input.cursor;
    c = *(++input.cursor);

    while(char_is_letter(c) || char_is_numeric(c) || c == "_")
      c = *(++input.cursor);

    var char* end_char = input.cursor - 1;
    var char* lexeme = install_id(arena, begin_char, end_char);

    token.kind = TokenKind_Id;
    token.lexeme = lexeme;
    var Token* keyword = lookup_keyword(keyword_list, lexeme);
    if(keyword)
      token.kind = keyword.kind;
  }
  else if(char_is_numeric(c))
  {
    var char digit_buf[32] = 0;
    var bool is_float = false;
    var int i = 0;
    for(; i < sizeof_array(digit_buf)-1 && (char_is_numeric(c) || c == "."); i++)
    {
      digit_buf[i] = c;
      if(c == ".")
      {
        if(is_float)
          break;
        is_float = true;
      }
      c = *(++input.cursor);
    }
    digit_buf[i] = "\0";

    if(is_float)
    {
      token.kind = TokenKind_FloatNum;
      token.float_val = mem_push_struct(arena, float, 1);
      sscanf(digit_buf, "%f", token.float_val);
    }
    else
    {
      token.kind = TokenKind_IntNum;
      token.int_val = mem_push_struct(arena, int, 1);
      sscanf(digit_buf, "%d", token.int_val);
    }
  }
  else if(c == "-")
  {
    token.kind = TokenKind_Minus;
    c = *(++input.cursor);
    if(c == "-")
    {
      token.kind = TokenKind_MinusMinus;
      ++input.cursor;
    }
    else if(is_leading_unary_token(get_prev_token(input, 0).kind))
    {
       token.kind = TokenKind_NegativeSign;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "*")
  {
    token.kind = TokenKind_Star;
    ++input.cursor;
    if(is_leading_unary_token(get_prev_token(input, 0).kind))
    {
      token.kind = TokenKind_Pointer;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "<")
  {
    token.kind = TokenKind_AngleLeft;
    c = *(++input.cursor);
    if(is_leading_unary_token(get_prev_token(input, 0).kind))
    {
      token.kind = TokenKind_Cast;
    }
    else
    {
      if(c == "=")
      {
        token.kind = TokenKind_AngleLeftEquals;
        ++input.cursor;
      }
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "&")
  {
    token.kind = TokenKind_Ampersand;
    c = *(++input.cursor);
    if(c == "&")
    {
      token.kind = TokenKind_AmpersandAmpersand;
      ++input.cursor;
    }
    else if(is_leading_unary_token(get_prev_token(input, 0).kind))
    {
      token.kind = TokenKind_AddressOf;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "/")
  {
    var char* fwd_cursor = input.cursor;

    c = *(++fwd_cursor);
    if(c == "*")
    {
      c = *(++fwd_cursor);

      while(true)
      {
        while(c != "*" && c != "\0")
        {
          if(c == "\n")
          {
            src_loc.line_nr++;
            src_loc.src_line = input.cursor;
          }
          c = *(++fwd_cursor);
        }
        if(c == "*")
        {
          c = *(++fwd_cursor);
          if(c == "/")
            break;
        } else if(c == "\0")
          break;
      }
      input.cursor = ++fwd_cursor;
    }
    else
    {
      token.kind = TokenKind_FwdSlash;
      token.lexeme = simple_lexeme_list[token.kind];
      ++input.cursor;
    }
  }
  else if(c == "'")
  {
    var char* fwd_cursor = input.cursor;

    c = *(++fwd_cursor);
    while(c != "'" && c != "\0")
      c = *(++fwd_cursor);

    if(c == "'")
    {
      var char* lexeme = install_dquot_str(arena, input.cursor, fwd_cursor);
      token.str = lexeme;
      token.kind = TokenKind_String;
      input.cursor = ++fwd_cursor;
    }
    else
      compile_error(&input.src_loc, "Missing closing '");
  }
  else if(c == "=")
  {
    token.kind = TokenKind_Equals;
    c = *(++input.cursor);
    if(c == "=")
    {
      token.kind = TokenKind_EqualsEquals;
      ++input.cursor;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == ">")
  {
    token.kind = TokenKind_AngleRight;
    c = *(++input.cursor);
    if(c == "=")
    {
      token.kind = TokenKind_AngleRightEquals;
      ++input.cursor;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "|")
  {
    token.kind = TokenKind_Pipe;
    c = *(++input.cursor);
    if(c == "|")
    {
      token.kind = TokenKind_PipePipe;
      ++input.cursor;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "!")
  {
    token.kind = TokenKind_Exclam;
    c = *(++input.cursor);
    if(c == "=")
    {
      token.kind = TokenKind_ExclamEquals;
      ++input.cursor;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "+")
  {
    token.kind = TokenKind_Plus;
    c = *(++input.cursor);
    if(c == "+")
    {
      token.kind = TokenKind_PlusPlus;
      ++input.cursor;
    }
    token.lexeme = simple_lexeme_list[token.kind];
  }
  else if(c == "%")
  {
    token.kind = TokenKind_Percent;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "_")
  {
    token.kind = TokenKind_BackSlash;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == ".")
  {
    token.kind = TokenKind_Dot;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "}")
  {
    token.kind = TokenKind_CloseBrace;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "{")
  {
    token.kind = TokenKind_OpenBrace;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "(")
  {
    token.kind = TokenKind_OpenParens;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == ")")
  {
    token.kind = TokenKind_CloseParens;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == ";")
  {
    token.kind = TokenKind_Semicolon;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == ",")
  {
    token.kind = TokenKind_Comma;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == ":")
  {
    token.kind = TokenKind_Colon;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "[")
  {
    token.kind = TokenKind_OpenBracket;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "]")
  {
    token.kind = TokenKind_CloseBracket;
    token.lexeme = simple_lexeme_list[token.kind];
    ++input.cursor;
  }
  else if(c == "\0")
  {
    token.lexeme = 0;
    token.kind = TokenKind_EndOfInput;
  }
  else
  {
    token.kind = TokenKind_Unknown;
    simple_lexeme_list[TokenKind_Unknown][0] = c;
    token.lexeme = simple_lexeme_list[TokenKind_Unknown];
  }
}
